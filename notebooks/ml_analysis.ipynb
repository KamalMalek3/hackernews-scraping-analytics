{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f33b265d",
   "metadata": {},
   "source": [
    "\n",
    "# Hacker News Engagement Analysis\n",
    "\n",
    "This notebook explores the combined dataset collected via Selenium, BeautifulSoup, and the Hacker News API. We perform exploratory analysis and build predictive models to understand what headline signals correlate with high engagement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e69ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "data_path = Path('data/processed/combined_dataset.csv')\n",
    "df = pd.read_csv(data_path)\n",
    "print(f\"Loaded {len(df)} records from {data_path}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e98056",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.describe(include='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b52812f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "sns.boxplot(data=df, x='method', y='points', ax=axes[0])\n",
    "axes[0].set_title('Points Distribution by Method')\n",
    "axes[0].set_xlabel('Scraping Method')\n",
    "axes[0].set_ylabel('Points')\n",
    "\n",
    "sns.boxplot(data=df, x='method', y='comments_count', ax=axes[1])\n",
    "axes[1].set_title('Comment Count Distribution by Method')\n",
    "axes[1].set_xlabel('Scraping Method')\n",
    "axes[1].set_ylabel('Comments')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea410ed",
   "metadata": {},
   "source": [
    "\n",
    "## Text Features and Binary Engagement Classification\n",
    "\n",
    "We label posts whose score falls in the top quartile as **high engagement** and train a\n",
    "regularized logistic regression model on TF-IDF features over the headlines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc9d461",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "threshold = df['points'].quantile(0.75)\n",
    "df['high_engagement'] = (df['points'] >= threshold).astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['title'], df['high_engagement'], test_size=0.25, random_state=42, stratify=df['high_engagement']\n",
    ")\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english', ngram_range=(1, 2), min_df=2)),\n",
    "    ('log_reg', LogisticRegression(max_iter=200, class_weight='balanced')),\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_proba):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3134460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inspect influential keywords\n",
    "import numpy as np\n",
    "\n",
    "vectorizer = clf.named_steps['tfidf']\n",
    "log_reg = clf.named_steps['log_reg']\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "coefs = log_reg.coef_[0]\n",
    "\n",
    "top_positive_idx = np.argsort(coefs)[-15:][::-1]\n",
    "top_negative_idx = np.argsort(coefs)[:15]\n",
    "\n",
    "print('Top positive signals (more likely high engagement):')\n",
    "for idx in top_positive_idx:\n",
    "    print(f\"  {feature_names[idx]:<20} {coefs[idx]:.3f}\")\n",
    "\n",
    "print('\n",
    "Top negative signals (less likely high engagement):')\n",
    "for idx in top_negative_idx:\n",
    "    print(f\"  {feature_names[idx]:<20} {coefs[idx]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dd0eb6",
   "metadata": {},
   "source": [
    "\n",
    "## Regression: Predict Exact Engagement\n",
    "\n",
    "We also fit a gradient boosting regressor to predict the exact point total from\n",
    "combined tabular features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe2c2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "df = df.copy()\n",
    "df['title_length'] = df['title'].str.len()\n",
    "df['question_mark'] = df['title'].str.contains('?', regex=False).astype(int)\n",
    "\n",
    "X = df[['title', 'title_length', 'question_mark', 'method']]\n",
    "y = df['points']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', TfidfVectorizer(max_features=1000, stop_words='english'), 'title'),\n",
    "        ('numeric', StandardScaler(), ['title_length', 'question_mark']),\n",
    "        ('onehot', 'passthrough', ['method']),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "reg_model = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('reg', GradientBoostingRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "reg_model.fit(X_train, y_train)\n",
    "\n",
    "preds = reg_model.predict(X_test)\n",
    "print(f\"MAE: {mean_absolute_error(y_test, preds):.2f}\")\n",
    "print(f\"R^2: {r2_score(y_test, preds):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e571bf",
   "metadata": {},
   "source": [
    "\n",
    "## Takeaways\n",
    "\n",
    "- API scraping provides the leanest bandwidth usage but omits rendered comment text, making it ideal for incremental polling.\n",
    "- Selenium captures interaction-heavy context but at significantly higher latency.\n",
    "- Headline phrasing containing terms like *Ask HN*, *Show HN*, or incident language tends to correlate with higher engagement.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
