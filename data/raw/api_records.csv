post_id,title,url,points,comments_count,author,top_comment_author,top_comment_text
45653143,Language Support for Marginalia Search,https://www.marginalia.nu/log/a_126_multilingual/,55,4,Bogdanp,mariusor,"Off topic, but would there be a way to integrate marginalia with a specific website? Similarly to how people use google search for their forums or how HN uses algolia?
I'm asking this as one of my projects is a link aggregator similar to old reddit (and HN to some extent) and I would like to be able to present to users a search box, but without having to implement document indexing and search. (I assume ad principio that the website is already aligned ethically and technologically with what Marginalia stands for :D)"
45640838,AWS multiple services outage in us-east-1,https://health.aws.amazon.com/health/status?ts=20251020,1923,349,kondro,time0ut,"Interesting day. I've been on an incident bridge since 3AM. Our systems have mostly recovered now with a few back office stragglers fighting for compute.
The biggest miss on our side is that, although we designed a multi-region capable application, we could not run the failover process because our security org migrated us to Identity Center and only put it in us-east-1, hard locking the entire company out of the AWS control plane. By the time we'd gotten the root credentials out of the vault, things were coming back up.
Good reminder that you are only as strong as your weakest link."
45652859,Practical Scheme,https://practical-scheme.net/index.html#docs,29,5,ufko_org,zippyman55,"My funny Scheme story.  My work place was using it in production, 1999. A ton of code was written by a VERY SMART (and famous) person and of course it worked.  He delivered it under pressure, ahead of schedule and it just worked.  Ok, but my frustration was that we could not find anyone to support the decoders. So, I could have 300 resumes, and zero would reference scheme.
So, there I was one Sunday, a church greeter, greeting people before church on a Sunday.  And a fellow greeter brought up software, and I somewhat went off on Scheme as to how difficult it was to find interview candidates for the system.
Then, I turn around to greet the next person, and he had a Fricken Scheme Polo Shirt with a prominent Lambda.  I am not sure if he heard me."
45653350,Show HN: I'm rewriting a web server written in Rust for speed and ease of use,https://ferron.sh/,10,2,dorianniemiec,earthnail,"Reach out to the guys at Kamal. They wrote their own reverse proxy because they thought Traefik was too complex, but they might be super happy about yours if Ferron is more powerful yet easy to configure because it might solve more of Kamal’s problems.
Not affiliated with Kamal at all, just an idea."
45653330,Pasta/80 is a simple Pascal cross compiler targeting the Z80 microprocessor,https://github.com/pleumann/pasta80,6,1,mariuz,benterix,"This made my heart melt:
<a href=""https://github.com/pleumann/pasta80/issues/7#issuecomment-2873679460"" rel=""nofollow"">https://github.com/pleumann/pasta80/issues/7#issuecomment-28...</a>"
45632429,A laser pointer at 2B FPS [video],https://www.youtube.com/watch?v=o4TdHrMi6do,405,16,thunderbong,estimator7292,"Tl:dw for how this works:
He scans one line at a time with a mirror into a photomultiplier tube which can detect single photon events. This is captured continually at 2MSample/s (2 billion times per second: 2B FPS) with an oscilloscope and a clever hack.
The laser is actually pulsing at 30KHz, and the oscilloscope capture is synchronized to the laser pulse.
So we consider each 30KHz pulse a single event in a single pixel (even though the mirror is rotating continuously). So he runs the experiment 30,000 times per second, each one recording a single pixel at 2B FPS for a few microseconds. Each pixel-sized video is then tiled into a cohesive image"
45617948,Show HN: I'm making a detective game built on Wikipedia,https://detective.wiki/,87,16,jasonsmiles,alex-moon,"This is beautifully designed and engaging and potentially a fun way to learn things! Amazing work.
Some things you could add to make it stickier:
1. Have a natural end where you ""win"" - possibly I just didn't hit this, it's the kind of game I'd play in bed in the morning as long as the play time was similar to Wordle and the other NYT games.
2. Have facts show up when you get something right! Could literally just be the opening sentence from the article and a link to the article. This extra context stimulates curiosity - I'd love to be able to have ""Space physics? That doesn't sound like a real thing..."" and then have the hat guy pop up and go, ""You cracked it chief. Space Physics is the study of high atmosphere plasmas.""
EDIT: for comparison, have a look at Metazooa - <a href=""https://metazooa.com/"" rel=""nofollow"">https://metazooa.com/</a> - which did this very well."
45584680,Bare Metal (The Emacs Essay),https://waxbanks.wordpress.com/2025/08/01/bare-metal-the-emacs-essay/,26,2,hpaone,billfruit,"While I still use emacs, I find that that despite the ""batteries included"" narrative about emacs, the things which are not included are causes of major frustration.
Such essential functionality like grep-find and LSP servers which is required for out of the box auto complete are not bundled with emacs. Most modern IDEs/editors have these functionality baked in.
If you install emacs for windows you find that grep-find doesn't work, because it depends on support from environment. A full text search should be built into the editor."
45643163,Alibaba Cloud says it cut Nvidia AI GPU use by 82% with new pooling system,https://www.tomshardware.com/tech-industry/semiconductors/alibaba-says-new-pooling-system-cut-nvidia-gpu-use-by-82-percent,422,15,hd4,kilotaras,"Alibaba Cloud claims to reduce Nvidia GPU <i>used for serving unpopular models</i> by 82% (emphasis mine)
> 17.7 per cent of GPUs allocated to serve only 1.35 per cent of requests in Alibaba Cloud’s marketplace, the researchers found
Instead of 1192 GPUs they now use 213 for serving those requests."
45645349,Production RAG: what I learned from processing 5M+ documents,https://blog.abdellatif.io/production-rag-processing-5m-documents,402,28,tifa2up,mediaman,"The point about synthetic query generation is good. We found users had very poor queries, so we initially had the LLM generate synthetic queries. But then we found that the results could vary widely based on the specific synthetic query it generated, so we had it create three variants (all in one LLM call, so that you can prompt it to generate a wide variety, instead of getting three very similar ones back), do parallel search, and then use reciprocal rank fusion to combine the list into a set of broadly strong performers. For the searches we use hybrid dense + sparse bm25, since dense doesn't work well for technical words.
This, combined with a subsequent reranker, basically eliminated any of our issues on search."
45644328,BERT is just a single text diffusion step,https://nathan.rs/posts/roberta-diffusion/,393,16,nathan-barry,jaaustin,"To my knowledge this connection was first noted in 2021 in <a href=""https://arxiv.org/abs/2107.03006"" rel=""nofollow"">https://arxiv.org/abs/2107.03006</a> (page 5). We wanted to do text diffusion where you’d corrupt words to semantically similar words (like “quick brown fox” -> “speedy black dog”) but kept finding that masking was easier for the model to uncover. Historically this goes back even further to <a href=""https://arxiv.org/abs/1904.09324"" rel=""nofollow"">https://arxiv.org/abs/1904.09324</a>, which made a generative MLM without framing it in diffusion math."
45578080,When Compiler Optimizations Hurt Performance,https://nemanjatrifunovic.substack.com/p/when-compiler-optimizations-hurt,40,5,rbanffy,president_zippy,"If you wanna really see this at work on a whole other extreme, try compiling code for an N64 game. It's no surprise that optimizations for modern-day x86_64 and Arm64 processors with a lot of cache would not generalize well to a MIPS CPU with a cache that must be manipulated at the software layer and abysmal RDRAM latency, but the exact mechanics of it are interesting.
KazeEmmanuar did a great job analyzing exactly this so we don't have to!
<a href=""https://www.youtube.com/watch?v=Ca1hHC2EctY"" rel=""nofollow"">https://www.youtube.com/watch?v=Ca1hHC2EctY</a>"
45571423,My trick for getting consistent classification from LLMs,https://verdik.substack.com/p/how-to-get-consistent-classification,191,14,frenchmajesty,minimaxir,"There is a flaw with the base problem: each tweet only has one label, while a tweet is often about many different things and can't be delinated so cleanly. Here's an alternate approach that both allows for multiple labels and lower marginal costs (albeit higher initial cost) for each tweet classified.
1. Curate a large representative subsample of tweets.
2. Feed all of them to an LLM in a single call with the prompt along the lines of ""generate <i>N</i> unique labels and their descriptions for the tweets provided"". This bounds the problem space.
3. For each tweet, feed them to a LLM along with the prompt ""Here are labels and their corresponding descriptions: classify this tweet with up to <i>X</i> of those labels"". This creates a synthetic dataset for training.
4. Encode each tweet as a vector as normal.
5. Then train a bespoke small model (e.g. a MLP) using tweet embeddings as input to create a multilabel classification model, where the model predicts the probability for each label that it is the correct one.
The small MLP will be super fast and cost effectively nothing above what it takes to create the embedding. It saves time/cost from performing a vector search or even maintaining a live vector database."
45555960,The Tyrrany of Literacy. On oral tradition and what is lost,https://languagelog.ldc.upenn.edu/nll/?p=71545,9,3,n2j3,ofalkaed,"The oral tradition is not lost, it just evolved to suit the times; urban myths and creepy pasta just have a lot more relevance. Literacy created the written tradition, moved writing past being just a medium for storage and transmission and moved the word beyond the limitations of speech. What really killed the oral tradition (in the sense TFA means) is technology, the ability to reproduce without error and the idea of ""correctness,"" the old myths ceased to evolve so new ones took their place."
45647166,Claude Code on the web,https://www.anthropic.com/news/claude-code-on-the-web,465,62,adocomplete,mmaunder,"We were heavy users of Claude Code ($70K+ spend per year) and have almost completely switched to codex CLI. I'm doing massive lifts with it on software that would never before have been feasible for me personally, or any team I've ever run. I'll use Claude Code maybe once every two weeks as a second set of eyes to inspect code and document a bug, with mixed success. But my experience has been that initially Claude Code was amazing and a ""just take my frikkin money"" product. Then Codex overtook CC and is much better at longer runs on hard problems. I've seen Claude Code literally just give up on a hard problem and tell me to buy something off the shelf. Whereas Codex's ability to profoundly increase the capabilities of a software org is a secret that's slowly getting out.
I don't have any relationship with any AI company, and honestly I was rooting for Anthropic, but Codex CLI is just way way better.
Also Codex CLI is cheaper than Claude Code.
I think Anthropic are going to have to somehow leapfrog OpenAI to regain the position they were in around June of this year. But right now they're being handed their hat."
45529120,I made a small LED panel,https://www.stavros.io/posts/really-small-led-panel/,73,9,Brajeshwar,stavros,"I was about to comment that I <i>also</i> made a small LED panel, but then realized it was me.
Here's the latest LED thing I'm working on (the design isn't mine): <a href=""https://immich.home.stavros.io/share/oXerU8gnLn-dNHunPOg8lM8jmQLbPqfYgCLWEiqmCUjifQlF_R0L4R0dgf1CKGAxTag"" rel=""nofollow"">https://immich.home.stavros.io/share/oXerU8gnLn-dNHunPOg8lM8...</a>"
45645120,Show HN: I created a cross-platform GUI for the JJ VCS (Git compatible),https://judojj.com,112,13,bitpatch,martinvonz,"Thanks for working on this project!
It was mentioned on the JJ Discord server that there doesn't seem to be any information available about who you are. Especially since the project seems to be closed-source, perhaps you could share some information about who you are in order to build trust.
I hope you understand. I think users may hesitate to download and install the application without knowing anything about its publisher."
45649178,Today is when the Amazon brain drain sent AWS down the spout,https://www.theregister.com/2025/10/20/aws_outage_amazon_brain_drain_corey_quinn/,617,44,raw_anon_1111,president_zippy,"Between the engineering staff and the warehouse workers, I wonder how long it will be until they have already fired everyone who ever would have been willing to work there.
Even with candidate pools of hundreds of thousands of H1-B engineers and tens of millions of illegal immigrant warehouse workers, there still comes a point where such a big company firing so many people so quickly exhausts all their options.
It reminds me of the Robot Chicken Sketch where Imperial Officers aboard the Death Star all pretend to be force choked to death by Darth Vader so they can avoid getting killed by lightsaber, then come back in under different names in different jobs. It's worse though for Amazon: nobody wants to come back.
<a href=""https://www.youtube.com/watch?v=fFihTRIxCkg"" rel=""nofollow"">https://www.youtube.com/watch?v=fFihTRIxCkg</a>"
45582958,ChkTag: x86 Memory Safety,https://community.intel.com/t5/Blogs/Tech-Innovation/open-intel/ChkTag-x86-Memory-Safety/post/1721490,241,19,ashvardanian,tdullien,"With all the negative comments here: This is existing technology on ARM64 (MTE) and on modern iPhones (<a href=""https://security.apple.com/blog/memory-integrity-enforcement/"" rel=""nofollow"">https://security.apple.com/blog/memory-integrity-enforcement...</a>).
For a good intuition why this (coupled with instrumenting all allocators accordingly) is a game-changer for exploitation, check <a href=""https://docs.google.com/presentation/d/1V_4ZO9fFOO1PZQTNODu2XarcXhlZTGaktBwc4EAHjL8/edit?usp=sharing"" rel=""nofollow"">https://docs.google.com/presentation/d/1V_4ZO9fFOO1PZQTNODu2...</a>
In general, having this come to x86 is long-overdue and very welcome."
45650792,Old Computer Challenge – Modern Web for the ZX Spectrum,https://0x00.cl/blog/2025/occ-2025/,42,8,0x00cl,userbinator,"Provided one had a network stack, it would've actually been possible to use Google on a ZX Spectrum until a short while ago, as it still listened on port 80 and the usual /search?q=<query goes here> was all that was necessary. Now Google has destroyed that, and even with HTTPS it refuses to do anything without JS."
